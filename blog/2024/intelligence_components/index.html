<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Different Components of Intelligence | Alexi Gladstone </title> <meta name="author" content="Alexi Gladstone"> <meta name="description" content="What are the different components of intelligence?"> <meta name="keywords" content="ai, artificial intelligence, ml, machine learning, alexi gladstone, philosophical, meaning of life"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%99%83&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://alexiglad.github.io/blog/2024/intelligence_components/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Alexi</span> Gladstone </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news </a> </li> <li class="nav-item "> <a class="nav-link" href="/services/">services </a> </li> <li class="nav-item"> <a class="nav-link" href="/assets/pdf/Alexi_Gladstone_CV.pdf" target="_blank" rel="noopener noreferrer"> cv <span class="sr-only">(current)</span> </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">The Different Components of Intelligence</h1> <p class="post-meta"> Created in September 14, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/intelligence"> <i class="fa-solid fa-hashtag fa-sm"></i> intelligence,</a>   <a href="/blog/tag/memorization"> <i class="fa-solid fa-hashtag fa-sm"></i> memorization,</a>   <a href="/blog/tag/few-shot-learning"> <i class="fa-solid fa-hashtag fa-sm"></i> few_shot_learning,</a>   <a href="/blog/tag/generalization"> <i class="fa-solid fa-hashtag fa-sm"></i> generalization,</a>   <a href="/blog/tag/creativity"> <i class="fa-solid fa-hashtag fa-sm"></i> creativity</a>   ·   <a href="/blog/category/ai"> <i class="fa-solid fa-tag fa-sm"></i> AI,</a>   <a href="/blog/category/evolution"> <i class="fa-solid fa-tag fa-sm"></i> evolution</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><em>It’s worth noting that most of this blog is not very scientific and is mostly just a useful abstraction for how to view the different components of intelligence (which is especially useful for thinking about current model capablities or benchmarking). The different aspects of intelligence are abstract ideas, don’t necesssarily represent the underlying way the mind works, and may not encompass all different portions of intelligence. If you come up with other aspects of intelligence please email me :)</em></p> <h3 id="1-memorization-and-knowledge">1) Memorization and Knowledge</h3> <p>Memorization broadly refers to the ability to recite information. Knowledge goes a step beyond this, and involves applying memorized information to new contexts. Knowledge often involves understanding at a deeper level than sole memorization.</p> <p>As of 2024, Large Language Models (LLMs) are pretty good at memorization and, are half decent at knowledge, but fail at most of the other aspects of intelligence discussed below.</p> <h3 id="2-learning-efficiency">2) Learning Efficiency</h3> <p>Because of evolution, it’s easy to see that most modern animals (<a href="https://pubmed.ncbi.nlm.nih.gov/24390479/" rel="external nofollow noopener" target="_blank">and even plants</a>), learn pretty efficiently.</p> <p><a id="image-experiment"></a> </p> <p><img src="/assets/img/blog/dog_experiment.png" alt="object choice task experiment"></p> <p>As an example of animal learning efficiency, if you put a treat on the floor under a cup, and then put down another cup (with the dog watching), and then point to the cup without a treat under it (<a href="#image-experiment">see example image</a>, <a href="https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Flink.springer.com%2F10.1007%2F978-3-319-47829-6_100-1&amp;psig=AOvVaw2cVxlE7-ZVPwfrL25o3WDF&amp;ust=1726449432306000&amp;source=images&amp;cd=vfe&amp;opi=89978449&amp;ved=0CBcQjhxqFwoTCLDCsbzjw4gDFQAAAAAdAAAAABAE" rel="external nofollow noopener" target="_blank">link</a>), <a href="https://www.psychologytoday.com/us/blog/canine-corner/201502/study-dogs-can-identify-liars-and-they-dont-trust-them" rel="external nofollow noopener" target="_blank">dogs may follow your point</a>. However, often after 1 or a few times doing this dogs will often learn <strong>not</strong> to trust your point. This example demonstrates that dogs will learn quickly given just a few or even 1 example/’shot’/trial.</p> <p>Within the context of AI, the idea of learning efficiency <a href="https://arxiv.org/abs/2205.06743" rel="external nofollow noopener" target="_blank">has long been a focus</a>. People often claim that modern models are great at zero-shot or few-shot learning… but is this really the case?</p> <p>I believe that “Zero-shot” learning (and few-shot similarly) can be interpreted in two distinct ways:</p> <ol> <li> <p><strong>Not seeing something at all during training and being able to predict it on the test set</strong>: E.g. if you were doing supervised classification, not seeing a dog at all during training, but knowing what a dog is during testing. This is a harder problem and, in my opinion, is impossible.</p> </li> <li> <p><strong>Not specifically training or learning for a downstream task but still being able to do the task</strong>: This is relatively easier and has been solved in some cases, such as CLIP for image recognition or LLMs being able to extract entities. These models were not trained for the specific task, yet are still able to perform it. It’s worth noting though, that these models have seen the concepts/tasks they are being tested on throughout pre-training (or some form of pre-training).</p> </li> </ol> <p>The first definition is the literal definition of zero-shot, while the latter definition is the more commonly used and easier version.</p> <p>So How Does Pre-Training Data Affect “Zero-Shot” Performance?</p> <p>The paper “<a href="https://arxiv.org/pdf/2404.04125" rel="external nofollow noopener" target="_blank">Do Multimodal Models Really Achieve Zero-Shot Generalization?</a>” states the following:</p> <blockquote> <p>“We consistently find that, far from exhibiting “zero-shot” generalization, multimodal models require exponentially more data to achieve linear improvements in downstream “zero-shot” performance, following a sample inefficient log-linear scaling trend.”</p> </blockquote> <p>This finding aligns with the second definition of “zero-shot”, and supports the idea that with modern AI we are still far from true zero or few shot generalization/learning efficiency (the first definition).</p> <p>Recent benchmarks, such as <a href="https://arcprize.org/" rel="external nofollow noopener" target="_blank">ARC-AGI</a>, further support this. ARC-AGI measures the abilities of models to learn a completely new task, given just a few examples and then perform that task. Humans can achieve nearly 100% on this benchmark, but modern LLMs only score around 21%, and top approaches score less than 50% (both of these values are based off of when this blog was written in 2024). It’s worth noting that problems in the benchmark get progressively (one could even say exponentially) more difficult, so the jump from 21% to 50% is <strong>very significantly</strong> easier than the jump from 50% to 100%.</p> <details> <summary>If you are now tempted to say, "What about LLMs which are great at few shot learning?"</summary> LLMs are not good at few shot learning unless they have already been trained on data similar to whatever task is being performed. For benchmarks such as ARC, which are completely out of distribution for the pre-training data of LLMs, they do terrible at few shot learning. AI researchers have become accustomed to calling models good at few shot learning, even though models have often seen similar examples during pre-training hundreds or even thousands of times during training. [Paper](https://arxiv.org/pdf/2404.04125) </details> <p><br></p> <h3 id="3-generalization-creativity-and-invention">3) Generalization, Creativity, and Invention</h3> <p>Generalization, in the context of intelligence, can broadly be defined as “the ability to apply learned knowledge or skills to new and varied situations.” Similarly, creativity can be thought of as “the ability to generate novel and original ideas or solutions by combining existing knowledge or skills in innovative ways<sup id="fnref:1"><a href="#fn:1" class="footnote" rel="footnote" role="doc-noteref">1</a></sup>.” It’s easy to see that the further someone is able to generalize, the better their creativity will likely be. It’s also worth noting that creativity and generalization are spectrums, and not binary skills that intelligent systems either do or don’t have.</p> <p>One cool thing about creativity, is that <em>great</em> creativity can lead to invention.</p> <p>Now, if we were to look at our society now, and compare it to societies from 1,000 years ago, 10,000 years, etc; the differences we’d see could be explained by one thing–invention. Inventions, one after another, have led to the revolutionization of our society. Without invention, humans would be no different than apes.</p> <h4 id="the-most-challenging-aspect-of-intelligence">The Most Challenging Aspect of Intelligence</h4> <p>I’ve ordered this blog based off of which aspects of intelligence I believe to be easiest (memorization, knowledge) to hardest (generalization). Although I don’t think I can argue for this ‘ordering of intelligence attributes’ scientifically, a simple evolutionary argument can be made. Animals, and even plants as we have seen, are capable of memorization and few shot learning. However, their abilities to invent with the same success as humans is limited. As such, we can say that humans have better generalization/creativity than other animals and plants, and that this is something extremely challenging to develop through intelligence (since only humans have it).</p> <h4 id="compression">Compression</h4> <p>Tons of AI researchers love mentioning how compression is linked/core to intelligence (<a href="https://arxiv.org/pdf/2309.10668" rel="external nofollow noopener" target="_blank">paper</a>, <a href="https://x.com/arankomatsuzaki/status/1780073500536872990" rel="external nofollow noopener" target="_blank">twitter mention</a>). I’ve always agreed with this statement. To me, however, it was never clear <em>why</em> (at least with an elegant explanation). I think the framework discussed in this blog to look at different aspects of intelligence provides a great lens, here’s how:</p> <p>Compression in an of itself is an aspect of memorization/knowledge. Let’s say animal A has compressed 1000 bits of information into 100 bits, and animal B compressed the same information into 10 bits. Both animals have memorized the same information.</p> <p>However, the difference in these memorizations, is that in the future, animal B will likely be able to generalize to more situations. Why, you ask? Intuitively, animal B has likely memorized more of the core reasoning/explanation than animal A, and that will likely explain future situations better. Mathematically, there are also some cool proofs for this (<a href="https://www.youtube.com/watch?v=AKMuA_TVz3A" rel="external nofollow noopener" target="_blank">Ilya talk</a>, <a href="https://arxiv.org/pdf/2304.09355" rel="external nofollow noopener" target="_blank">related paper</a>).</p> <p>Therefore, we can see that further compression of the same information leads to better generalization. As discussed, I believe generalization is likely the most challenging aspect of intelligence, and hence compression is likely core to high levels of intelligence.</p> <p>Perhaps the saying “simplicity is key” hits a bit harder after learning this :)</p> <h4 id="generalization-of-modern-models">Generalization of Modern Models</h4> <p>While some recent papers have stated that LLMs can come up with novel ideas and do research at the level of humans (<a href="https://arxiv.org/pdf/2409.04109" rel="external nofollow noopener" target="_blank">paper1</a>, <a href="https://www.arxiv.org/pdf/2408.06292" rel="external nofollow noopener" target="_blank">paper2</a>), there are numerous problems with the methodology of these papers (that I don’t have the time to write about). If these papers really did work well, then people doing frontier research would be using LLM generated ideas, rather than what people are doing now which is having real humans do research. LLMs, being trained to predict the next token over existing text corpuses online, are nowhere near being capable of generating their own creative ideas that will eventually lead to technological invention. (I’m not claiming here that LLMs can’t assist in the idea generation process, as I agree they are helpful with that. Rather, I’m claiming they are nowhere near being able to generate <em>their own</em>, <strong>good</strong> ideas.)</p> <h3 id="summary">Summary</h3> <p>AI in 2024 (mostly dominated by LLMs) is capable of memorization and knowledge to a wide extent. However, modern models fall short of being able to learn efficiently (few-shot), and are nowhere near being able to generalize to the same extent as humans. As most plants and animals are capable of sample efficient learning, I have no doubt that eventually we will have AI that learns as efficiently as plants and animals. To me, the quadrillion dollar problem is–how do humans generalize so well (so much better than even close ancestors such as apes)? And how will we ever train models to be able to generalize to the same extent as humans, such that they can come up with really great ideas that revolutionize society. <a href="https://alexiglad.github.io/blog/2023/biological_intelligence/">I have a blog about this very topic!</a></p> <h2 id="footnotes">Footnotes</h2> <div class="footnotes" role="doc-endnotes"> <ol> <li id="fn:1"> <p>One may be tempted to say that creativity need not be defined by composing observations/existing knowledge (i.e. that we can generate entirely new ideas). First, modern research points to the fact that humans are likely generating new ideas based off of combinations of past experiences/observations. Second, as an informal experiment, try thinking of something completely new that is not composed of previous things you have seen/heard/etc. If you manage to succeed at this task (which I would be very surprised about), ask ChatGPT to see if it is truly novel or can be decomposed. If that isn’t convincing, email me, and I’ll try and convince you that you are wrong :). <a href="#fnref:1" class="reversefootnote" role="doc-backlink">↩</a></p> </li> </ol> </div> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/EBWM/">EBWM: Cognitively Inspired Energy-Based World Models</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/improving_governments/">How Can We Improve Governments?</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/neuroplasticity_hypothesis/">The Neuroplasticity Hypothesis</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/biological_intelligence/">Does Biological Intelligence Have Any Advantages Over Digital Intelligence?</a> </li> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'alexiglad/alexiglad.github.io',
        'data-repo-id': 'R_kgDOJMn35A',
        'data-category': 'Announcements',
        'data-category-id': 'DIC_kwDOJMn35M4CmZpV',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Alexi Gladstone. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?70d799092f862ad98c7876aa47712e20"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>